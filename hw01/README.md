## Word Embeddings

This project was done as part of Deep Learning in NLP (LING530F) course. In this, we explore basic NLP preprocessing techniques to identify most frequent nouns,adjectives,pronouns etc. We also learn about the hyperparameters of word2vec model and their significance. 

The final notebook file can be found [here](https://nbviewer.jupyter.org/github/abishekarun/LING530F/blob/master/hw01/Assignment1.ipynb) and the rendered pdf can be found [here](https://github.com/abishekarun/LING530F/blob/master/hw01/Assignment_1.pdf).

The resources that helped me are:

+ [Downloading files from google drive](https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url)
+ [Pos tagging](https://www.nltk.org/book/ch05.html)
+ [Barplot with labels](https://stackoverflow.com/questions/45080698/make-frequency-histogram-from-list-with-tuple-elements) 
+ [Gensim Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec)