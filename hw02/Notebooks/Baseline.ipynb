{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JrUKpfUIKZ37"
   },
   "source": [
    "<h1 align=\"center\">LING530F: Deep Learning for NLP</h1>\n",
    "<h1 align=\"center\">Assignment 2 : Implicit Emotion Detection</h1>\n",
    "<h1 align=\"center\">Traditional Machine Learning Models</h1>\n",
    "<h2 align=\"center\"> Arun Rajendran(86611860)</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTHaWDOdyUC4"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install GoogleDriveDownloader\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "uxtzDDZfL8Jb",
    "outputId": "f3b04b0f-8447-44c0-8b75-c5ec8a6a2eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 11surQQr3jbmzHDKgEA5c46CKA23Nf7PA into data/dev.csv... Done.\n",
      "Downloading 1TokPKns1uZRAW-GDN0fUz259haU2ZZAW into data/test.csv... Done.\n",
      "Downloading 1oBiUaUHLrXehWF570xLyQNTjD9QU4fPY into data/train.csv... Done.\n",
      "Downloading 1ewgcXWBioeMVJlKsZK9gLv3hWxGDqmiz into data/trial-v3.labels... Done.\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='11surQQr3jbmzHDKgEA5c46CKA23Nf7PA',                                 # Id of file to be downloaded\n",
    "                                    dest_path='data/dev.csv')                                                    # Destination path\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1TokPKns1uZRAW-GDN0fUz259haU2ZZAW',                                 # Id of file to be downloaded\n",
    "                                    dest_path='data/test.csv')                                                    # Destination path\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1oBiUaUHLrXehWF570xLyQNTjD9QU4fPY',                                 # Id of file to be downloaded\n",
    "                                    dest_path='data/train.csv')                                                    # Destination path\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1ewgcXWBioeMVJlKsZK9gLv3hWxGDqmiz',                                 # Id of file to be downloaded\n",
    "                                    dest_path='data/trial-v3.labels')                                                    # Destination path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1At6Uyvklpk"
   },
   "outputs": [],
   "source": [
    "# Replace the fake labels in dev file with correct labels\n",
    "labels = open('data/trial-v3.labels','r').readlines()\n",
    "lines = open('data/dev.csv','r').readlines()\n",
    "correct_lines=[]\n",
    "for label, line in zip(labels, lines):\n",
    "        line=line.rstrip('\\n')\n",
    "        text = line.split(',')\n",
    "        text[0]=label\n",
    "        correct_line=[''.join(text[0]),''.join(text[1:])]\n",
    "        correct_lines.append(correct_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiYQ3JHIoNEN"
   },
   "outputs": [],
   "source": [
    "# Write the clean dev data in new file\n",
    "out = open('data/clean_dev.csv',mode='w')                                      \n",
    "for line in correct_lines:\n",
    "    line[0]=line[0].rstrip('\\n')\n",
    "    out.write(line[0])\n",
    "    out.write(',')\n",
    "    out.write(line[1])\n",
    "    out.write('\\n')\n",
    "out.close()                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "kWVrpc4XM-uH",
    "outputId": "395cf7d3-89c5-4ba9-9f49-670af208f1a8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read train and dev data\n",
    "%%capture\n",
    "import pandas as pd\n",
    "X_train = pd.read_table('data/train.csv',sep=',',index_col=False, error_bad_lines=False)\n",
    "X_test = pd.read_csv('data/clean_dev.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "MQO3foldOjxm",
    "outputId": "7f5fa3a2-7ced-4a7b-fea8-b41fe89fdebf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>@USERNAME A little [#TRIGGERWORD#] that I am n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@USERNAME @USERNAME It's pretty [#TRIGGERWORD#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>Apparently I've been black mailing my brother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>Republicans are so [#TRIGGERWORD#] that people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>Katy once felt so [#TRIGGERWORD#] that she bar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@USERNAME @USERNAME I'm ever more [#TRIGGERWOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@USERNAME @USERNAME Woohoo! I'm [#TRIGGERWORD#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@USERNAME — pain I'm in from being so lonely. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>pretty [#TRIGGERWORD#] that a white republican...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sad</td>\n",
       "      <td>@USERNAME no cause I don't wanna be that [#TRI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet\n",
       "0     anger  @USERNAME A little [#TRIGGERWORD#] that I am n...\n",
       "1   disgust  @USERNAME @USERNAME It's pretty [#TRIGGERWORD#...\n",
       "2      fear  Apparently I've been black mailing my brother ...\n",
       "3      fear  Republicans are so [#TRIGGERWORD#] that people...\n",
       "4       sad  Katy once felt so [#TRIGGERWORD#] that she bar...\n",
       "5  surprise  @USERNAME @USERNAME I'm ever more [#TRIGGERWOR...\n",
       "6   disgust  @USERNAME @USERNAME Woohoo! I'm [#TRIGGERWORD#...\n",
       "7  surprise  @USERNAME — pain I'm in from being so lonely. ...\n",
       "8   disgust  pretty [#TRIGGERWORD#] that a white republican...\n",
       "9       sad  @USERNAME no cause I don't wanna be that [#TRI..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "kyZSIMgdq4an",
    "outputId": "33728c4d-4cae-47a0-b23a-c764676e3858"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@USERNAME I'm just [#TRIGGERWORD#] that Sears ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>Adjoa looks [#TRIGGERWORD#] that Nick has put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>A key component of why it's so much fun to rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>I am [#TRIGGERWORD#] that these women are bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@USERNAME really?! That's actually [#TRIGGERWO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sad</td>\n",
       "      <td>It's very [#TRIGGERWORD#] that Presidents even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@USERNAME not all but a lot of humans are [#TR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sad</td>\n",
       "      <td>@USERNAME how does it make you [#TRIGGERWORD#]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@USERNAME @USERNAME [#TRIGGERWORD#] when elsew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>joy</td>\n",
       "      <td>make you feel like you're not good enough dump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label1                                              tweet\n",
       "0  surprise  @USERNAME I'm just [#TRIGGERWORD#] that Sears ...\n",
       "1   disgust  Adjoa looks [#TRIGGERWORD#] that Nick has put ...\n",
       "2      fear  A key component of why it's so much fun to rea...\n",
       "3   disgust  I am [#TRIGGERWORD#] that these women are bein...\n",
       "4  surprise  @USERNAME really?! That's actually [#TRIGGERWO...\n",
       "5       sad  It's very [#TRIGGERWORD#] that Presidents even...\n",
       "6   disgust  @USERNAME not all but a lot of humans are [#TR...\n",
       "7       sad  @USERNAME how does it make you [#TRIGGERWORD#]...\n",
       "8   disgust  @USERNAME @USERNAME [#TRIGGERWORD#] when elsew...\n",
       "9       joy  make you feel like you're not good enough dump..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhPWiDbUPQNm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,HashingVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()  \n",
    "  \n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "1kiX4sDCPT66",
    "outputId": "2d5a1b5e-4893-4180-c8aa-042234193614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         27672\n",
       "disgust     25351\n",
       "surprise    25183\n",
       "anger       25180\n",
       "fear        24991\n",
       "sad         22980\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrYHJg_QjGYy"
   },
   "outputs": [],
   "source": [
    "def lemmatize_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    lm_tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lm_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZLr1XzKPNRi"
   },
   "outputs": [],
   "source": [
    "def clean_text(content):\n",
    "  content=content.str.lower()                                                         # Convert to Lowercase\n",
    "  content=content.str.replace('#triggerword#','')                                     # Remove triggerword tags\n",
    "  content=content.str.replace('username','')                                          # Remove username tags\n",
    "  content=content.str.replace('http\\S+|www.\\S+', '')                                  # Remove Links\n",
    "  content=content.str.replace('\\s+', ' ')                                             # Remove multiple spaces\n",
    "  content=content.str.replace('[^A-Za-z\\s]+', '')                                     # Remove irrelevant characters other than alphabets and space\n",
    "  #content=content.apply(lemmatize_sentences)\n",
    "  return content\n",
    "  # Stemming\n",
    "  # Remove sparse terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtP0RkoNSmPW"
   },
   "outputs": [],
   "source": [
    "X_train['tweet'] = clean_text(X_train['tweet'])\n",
    "X_test['tweet']=clean_text(X_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "9_yd6rzYWdmi",
    "outputId": "61c86bef-8216-4aee-e190-e2daa0d83ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a little  that i am not invited for drinks an...\n",
       "1      its pretty  that there would even be stock p...\n",
       "2    apparently ive been black mailing my brother s...\n",
       "3    republicans are so  that people may treat peop...\n",
       "4    katy once felt so  that she barely had the str...\n",
       "5      im ever more  that potus  flotus take it in ...\n",
       "6      woohoo im  because i breastfed my babies in ...\n",
       "7      pain im in from being so lonely but im  that...\n",
       "8    pretty  that a white republican man keeps intr...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tweet[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpkdDcG0P-iL"
   },
   "outputs": [],
   "source": [
    "y_train=X_train.label\n",
    "X_train = X_train.drop(['label'],axis=1)\n",
    "y_test=X_test.label1\n",
    "X_test = X_test.drop(['label1'],axis=1)\n",
    "\n",
    "# Label encode the target variable of train & dev data\n",
    "le1=LabelEncoder()\n",
    "y_train=le1.fit_transform(y_train)\n",
    "\n",
    "le2=LabelEncoder()\n",
    "y_test=le2.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FlrNAaJNQWhG",
    "outputId": "2c85600c-4857-4097-f5a5-f263001f5de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Term Frequency Matrix:  (151357, 3747354)\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from text files\n",
    "count_vect = CountVectorizer(ngram_range=(1,4))\n",
    "X_train_counts = count_vect.fit_transform(X_train.tweet)\n",
    "X_test_counts =count_vect.transform(X_test.tweet)\n",
    "print('Shape of Term Frequency Matrix: ',X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QFlf9fvtQeAf",
    "outputId": "d4f2cd67-dcb6-425e-c0ea-584d3acf7659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5852394508367251"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine Learning\n",
    "# Training Naive Bayes (NB) classifier + BOW model\n",
    "clf = MultinomialNB().fit(X_train_counts,y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "to0sHkJoCvsQ",
    "outputId": "9b2a2b71-3b4d-4bc0-9061-c59d83802895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5977939767338595"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Linear SVM classifier + BOW model\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(X_train_counts,y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-7iJ25IhxsI7",
    "outputId": "0b7974ad-b029-4aff-e023-172a5e050eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5724634386982159"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Logisitic Regression(LogReg) classifier + BOW model \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial').fit(X_train_counts,y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbYfbHGDC_iD"
   },
   "outputs": [],
   "source": [
    "def print_acc(model):\n",
    "    y_pred = model.predict(X_test.tweet)\n",
    "    mirco_f1= f1_score(y_test, y_pred, average='macro')\n",
    "    print(mirco_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0fRXa6M-F-pE",
    "outputId": "352b9e61-ba9b-4bc4-eba3-71d451268355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123916337902315\n"
     ]
    }
   ],
   "source": [
    "# Training SVM + BOW + TF-IDF model\n",
    "\n",
    "svm_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))), ('tfidf', TfidfTransformer()), ('clf', LinearSVC())])\n",
    "svm_clf = svm_clf.fit(X_train.tweet,y_train)\n",
    "print_acc(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AExck43oxblH",
    "outputId": "39ec9862-6f04-466d-de66-8c4209120999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57275368417417\n"
     ]
    }
   ],
   "source": [
    "# Training NB + BOW + TF-IDF model\n",
    "\n",
    "nb_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.tweet,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nzPd4CrDVKMx",
    "outputId": "101a60b5-50ee-4b78-e1f3-5853af5fe2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582516756775786\n"
     ]
    }
   ],
   "source": [
    "# Training LogReg + BOW + TF-IDF model\n",
    "\n",
    "lg_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))), ('tfidf', TfidfTransformer()), ('clf', LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial'))])\n",
    "lg_clf = lg_clf.fit(X_train.tweet,y_train)\n",
    "print_acc(lg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "shSKgllgq9xY",
    "outputId": "ee0bf2b2-44e4-4c25-b8d5-f1c974809b4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046228524717893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Training Ensemble model\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "model2 = MultinomialNB()\n",
    "model3 = LinearSVC()\n",
    "# create the ensemble model\n",
    "eclf1 = VotingClassifier(estimators=[('lr', model1), ('nb', model2), ('svm', model3)], voting='hard')\n",
    "ensemble = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))), ('tfidf', TfidfTransformer()), ('clf', eclf1)])\n",
    "ensemble = ensemble.fit(X_train.tweet, y_train)\n",
    "print_acc(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "NLTK: Stemming and Lemmatization<br\\>\n",
    "https://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization\n",
    "\n",
    "Apply Stemmer to a column<br\\>\n",
    "https://stackoverflow.com/questions/43795310/apply-porters-stemmer-to-a-pandas-column-for-each-word\n",
    "\n",
    "Ensemble: Voting Classifier<br\\>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "\n",
    "Sample Pipeline<br\\>\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
    "\n",
    "TorchText and LSTM<br\\>\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "TorchText and CNN<br\\>\n",
    "https://github.com/DSKSD/DeepNLP-models-Pytorch/blob/master/notebooks/08.CNN-for-Text-Classification.ipynb\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "Saving and loading Pytorch Model<br\\>\n",
    "https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "\n",
    "Self Attention Explained<br\\>\n",
    "https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#self-attention\n",
    "\n",
    "Self Attention Code for LSTM<br\\>\n",
    "https://github.com/prakashpandey9/Text-Classification-Pytorch/blob/master/models/LSTM_Attn.py\n",
    "\n",
    "LSTM + CNN model \n",
    "https://discuss.pytorch.org/t/cnn-layer-in-the-top-of-lstm/7941/5\n",
    "https://discuss.pytorch.org/t/solved-concatenate-time-distributed-cnn-with-lstm/15435/4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
